---
title: "Confusion Tables"
author: "Jill Deines"
date: "Sunday, November 20, 2016"
output: 
  html_document:
    toc: yes
---

Goal: Accuracy assessment via confusion tables

```{r knitrOpts, echo=FALSE}
library(knitr)
opts_chunk$set(cache=FALSE, cache.path='cache/5.0_confusion/',
               fig.path='figure/5.0_confusion/')
```

**R Packages Needed**

```{r packages, message=FALSE, echo=TRUE}
library(rgdal)
library(caret)


# source project helper functions
source('functions/GeeCsvToSpdf.R')
source('functions/prettyConfusion.R')
```

## 2001
From Brian Wardlow's Kansas dataset of validation points, clipped to the RRB and manually cleaned for bad location points.

```{r Wardlow}
# load data
dataDir <- 'C:/Users/deinesji/Google Drive/GEE_tableExports/Accuracy_PointsforConfusionTables_test1_clean'
file2001 <- '2001_Wardlow_confusionData_RRB_test2_nosoy_noag.csv'
wardlow01 <- read.csv(paste(dataDir, file2001, sep='/'))

# lookup table for classification codes
predictedCode = data.frame(classification = c(0:2),
                       predictedClass = c('Dryland','Irrigated','Noncrop'))
referenceCode = data.frame(ClassCats = c(0:2),
                       referenceClass = c('Dryland','Irrigated','Noncrop'))
# add category names
wardlow01 <- merge(wardlow01, predictedCode)
wardlow01 <- merge(wardlow01, referenceCode)

# confusion table
wardlowConfusion <- confusionMatrix(data = wardlow01$predictedClass, 
                                      reference = wardlow01$referenceClass)

# make it pretty
wardlow.ct <- prettyConfusion(wardlowConfusion)

kable(wardlow.ct, digits=1)
```

## 2007
Jill's points for the Middle Republican 2007; I think I used 60% of the points for "validation" and am saving 40% for "test"

```{r midRep2007}
# load data
dataDir <- 'C:/Users/deinesji/Google Drive/GEE_tableExports/Accuracy_PointsforConfusionTables_test1_clean'
file2007 <- '2007_MidRep60_confusionData_RRB_test2_nosoy_noag.csv'
midRep07 <- read.csv(paste(dataDir, file2007, sep='/'))

# lookup table for classification codes
predictedCode = data.frame(classification = c(0:2),
                       predictedClass = c('Dryland','Irrigated','Noncrop'))
referenceCode = data.frame(classNum = c(0:2),
                       referenceClass = c('Dryland','Irrigated','Noncrop'))
# add category names
midRep07 <- merge(midRep07, predictedCode)
midRep07 <- merge(midRep07, referenceCode)

# confusion table
midRep07confusion <- confusionMatrix(data = midRep07$predictedClass, 
                                      reference = midRep07$referenceClass)

# make it pretty
midrep07.ct <- prettyConfusion(midRep07confusion)

kable(midrep07.ct, digits=1)
```


## 2010
Jill's points for the Middle Republican 2010; I think I used 20% of the points for "validation" and the other 80% were training


```{r midRep2010}
# load data
dataDir <- 'C:/Users/deinesji/Google Drive/GEE_tableExports/Accuracy_PointsforConfusionTables_test1_clean'
file2010 <- '2010_MidRep60_confusionData_RRB_test2_nosoy_noag.csv'
midRep10 <- read.csv(paste(dataDir, file2010, sep='/'))

# lookup table for classification codes
predictedCode = data.frame(classification = c(0:2),
                       predictedClass = c('Dryland','Irrigated','Noncrop'))
referenceCode = data.frame(classNum = c(0:2),
                       referenceClass = c('Dryland','Irrigated','Noncrop'))
# add category names
midRep10 <- merge(midRep10, predictedCode)
midRep10 <- merge(midRep10, referenceCode)

# confusion table
midRep10confusion <- confusionMatrix(data = midRep10$predictedClass, 
                                      reference = midRep10$referenceClass)

# make it pretty
midrep10.ct <- prettyConfusion(midRep10confusion)

kable(midrep10.ct, digits=1)
```
