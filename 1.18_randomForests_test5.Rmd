---
title: "Random Forest"
author: "Jill Deines"
date: "April 4, 2017"
output: 
  html_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=FALSE,
                      cache.path='cache/1.18_rrbRandFor_test5/',
               fig.path='figure/1.18_rrbRandFor_test5/')
```

Goal: Run a variable importance test on a random forest of my training points

Secondary goal unlikely to be obtained: use more functions below, less copy/pasting. Oh well, we can't all be beautiful.

update 4/24/2017: compared 2 class classifier in R with GEE

update 4/7/2017: did variable importance on 2 class classifier. Need to run metrics.

update 4/4/2017: This version uses the annual-based classifier only to slim down this mess.

Update: 2/26/2017 - Classify the MidRep validation points with R's random forest tree and compare with GEE's classification. Use GEE accuracy for 'test3_randomForets_500' for this, prior to any cleaning

Update 3/7/2017 - apply variable importance reduction to optimize classification on midrep validatin points

Update 3/21/2017 - run the R random forest on the test dataset points

randomForest package implementation:
 reference implementation based on CART trees
(Breiman, 2001; Liaw and Wiener, 2008)
â€“ for variables of different types: biased in favor of
continuous variables and variables with many categories
(Strobl, Boulesteix, Zeileis, and Hothorn, 2007)


**R Packages Needed**

```{r packages, message=FALSE, echo=TRUE}
library(gridExtra)
library(randomForest)
library(varSelRF)
library(caret)
library(knitr) # for 'kable' table display
library(tidyr)
library(ggplot2)
library(grid)

source('functions/prettyConfusion.R')
source('functions/testToConfusion.R')
source('functions/testToConfusion_GEE.R')
```

## Load Data
Load training point data used in GEE classification. These were processed in 1.16_trainingPoints_RRB.Rmd, which involved combining 2010 and 2012 points and removing extraneous columns, so that only the variables and a masterType and masterNum columns remained. I wrote out a csv version of the final kml to be used here.

```{r loadData}
# load kml of combined 2010/2012 training points
trainingFolder <- 'C:/Users/deinesji/Dropbox/1PhdJill/hpa/irrigation/data/GIS/training'
trainingName <- '2010_2012_COMBINED_training_12class_v2.csv'

points <- read.csv(paste0(trainingFolder, '/', trainingName))

# re-class the master types into 2 categories: irrigated, notirrigated
typeConverter2 <- data.frame(masterType = unique(points$masterType),
            classes = c('irrigated','notirrigated','irrigated','notirrigated',                             'irrigated','notirrigated','irrigated','notirrigated',                             'irrigated','notirrigated','notirrigated','notirrigated'))
points.binary  <- merge(points, typeConverter2)

# make a dataset without dryland soy
pointsNoSoy.bin <- points.binary[points.binary $masterType != 'soy_dryland',]
pointsNoSoy2.bin <- pointsNoSoy.bin[ , -which(names(pointsNoSoy.bin) %in%
                                        c('masterType','masterNum'))]

# make an annual variable dataset without dryland soy
columnsWanted <- c('EVI_max_14','EVI_range_14','GI_max_14','GI_range_14',
                   'NDVI_max_14','NDVI_range_14','NDWI_max_14','NDWI_range_14',
                   'aridity','b1','b1_1','greenArid','ndwi_gi','pdsi_ann',
                   'pdsi_grow','pr_ann','pr_early','pr_grow','pr_paw','slope_mean',
                   'classes')
annualBinary <- pointsNoSoy2.bin[, columnsWanted]
```


## Random Forest

### Annual random forest
Apply a random forest that mimics my GEE classification (500 trees, no dryland soy class, binary irrigated/not-irrigated output)

This dataset doesn't include dryland soy, nor any monthly variables (extracted above in the load data chunk). 

Run the classifier

```{r rf500_annual_binary, fig.height=6}
# run a random forest on all variables
set.seed(415)
fit500.annBin <- randomForest(x = annualBinary[,1:20], # all variable columns 
                    y = as.factor(annualBinary$classes),
                    ntree = 500,
                    importance = TRUE)

# look at variable importance
varImpPlot(fit500.annBin)
VI_F.annBin <- importance(fit500.annBin)[,'MeanDecreaseGini']
par(mar=c(7,4,4,2))
barplot(VI_F.annBin/sum(VI_F.annBin), las=3)
```


### Variable Importance - 2 classes
Tianfang suggested averaging variable importance scores for 20 random seeds

```{r variableImportance2, fig.width = 3}
# generate 20 random seeds
set.seed(32)
seed20 <- round(runif(n = 20, min = 0, max = 8000))

# a list to store output
annual2 <- list()

# run random forest for each seed, store in list
for (i in 1:length(seed20)) {
  set.seed(seed20[i])
  rf.fit <- randomForest(x = annualBinary[,1:20], # all variable columns 
                    y = as.factor(annualBinary$classes),
                    ntree = 500,
                    importance = TRUE)
  # get variable importance
  annual2[[i]] <- importance(rf.fit)[,3:4]
}

# reduce list by taking means
mean2 <- as.data.frame(Reduce(`+`, annual2) / length(annual2))

# format
mean2$variable <- rownames(mean2)

# add each variable's short name
mean2$shortname = c('EVI max','EVI range','GI max', 'GI range',                 
                    'NDVI max','NDVI range','NDWI max','NDWI range',                                     'Aridity','PAW-cm','PAW-Vol','AGI',
                    'WGI','PDSI-Late','PDSI-Grow','Ppt-Grow',
                    'Ppt-Early','Ppt-Late','Ppt-PAW','Slope')

mean2long <- gather(mean2, key = metric, value = value, 
                    MeanDecreaseAccuracy:MeanDecreaseGini)

# plot
p2 <- ggplot(mean2long[mean2long$metric == 'MeanDecreaseGini',],
       aes(x=reorder(shortname, value), y = value)) +
  geom_bar(stat='identity') +
  coord_flip() +
  theme_bw() + ylab('Mean Decrease in GINI Index') + xlab('') +
  theme(legend.title=element_blank(),
        axis.text=element_text(size=10),
        legend.text=element_text(size=10),
        axis.title=element_text(size=11),
        panel.grid = element_blank())

p1 <- ggplot(mean2long[mean2long$metric == 'MeanDecreaseAccuracy',],
       aes(x=reorder(shortname, value), y = value)) +
  geom_bar(stat='identity') +
  coord_flip() +
  theme_bw() + ylab('Mean Decrease in Accuracy') + xlab('') +
  theme(legend.title=element_blank(),
        axis.text=element_text(size=10),
        legend.text=element_text(size=10),
        axis.title=element_text(size=11),
        panel.grid = element_blank())
p1
```

combine plots

```{r variableImpt_nice_dark, fig.width=6.5, fig.height=6, dpi=600, dev=c('png','pdf')}
grid.newpage()
grid.draw(cbind(ggplotGrob(p1), ggplotGrob(p2), size = "last"))
```


### Play with variable reduction
without dryland soy. Here are the "most important" variables.

```{r varReduction_noDsoy, cache=TRUE}
# annual
atest <- varSelRF(xdata = annualBinary[,1:20], whole.range=F,
                    Class = as.factor(annualBinary$classes),
                    ntree = 500)
atest
```


## Test Datasets: Compare accuracy: GEE & R 
Checked after settling on the random forest, 500 tree, annual variables (20 variables) method, run without soy training points. This gives accuracy from the R classification; accuracies will also be carried out on the GEE outputs (including 1x majority filter and interannual cleaning - see 5.055_Confusion Tables_Final_test4_randFor.Rmd).

### R-based Annual classifier
on the full test point datasets for 2002 and 2015

```{r testPoints_annual2_all}
# load points and variable data
vpointFolder <- 'C:/Users/deinesji/Google Drive/GEE_validation/validationSets'
p2015 <- read.csv(paste0(vpointFolder, 
                         '/2015_data_randAll_1250_jmd_annual.csv'))
p2002 <- read.csv(paste0(vpointFolder,
                         '/2002_data_NE_randAll_1050_jmd_annual.csv'))

# 2015, certainty level 1 & 2, 2 classes, annual
c2015_all_2_ann <- testToConfusionBinary(dataset = p2015, numClasses = 2, 
                                    certainty = 2, classifier = fit500.annBin)
kable(c2015_all_2_ann, digits=1)


# 2002, certainty level 1 & 2, 2 classes, annual
c2002_all_2_ann <- testToConfusionBinary(dataset = p2002, numClasses = 2, 
                                    certainty = 2, classifier = fit500.annBin)
kable(c2002_all_2_ann, digits=1)
```

### GEE classifier
test 5 maps, uncleaned

```{r compare, cache=TRUE, eval=FALSE}
# load GEE accuracy tables locations
accuDir <- 'C:/Users/deinesji/Google Drive/GEE_tableExports/Accuracy_PointsforConfusionTables_test5_randFor'
g2002 <- '2002_RRB_NE_annual_confusionData_RRB_test5_randFor_uncleaned_500tree_binary_annual.csv'
g2015 <- '2015_RRB_annual_confusionData_RRB_test5_randFor_uncleaned_500tree_binary_annual.csv'

# get confusion tables
g2002.con <-  testToConfusionGee(datadir = accuDir, dataname = g2002,
                                 bandName = 'classification', certainty = 2)
kable(g2002.con, digits=1)

# get confusion tables
g2015.con <-  testToConfusionGee(datadir = accuDir, dataname = g2015,
                                 bandName = 'classification', certainty = 2)
kable(g2015.con, digits=1)
```

it looks like 2 different for 2002: 99.8% accurate (1 - 2/2013)

## Compare: validation datasets (middle republican)

### Make predictions in R
This uses the R random forest classifier created above to predict the classes of the MidRep validation points

```{r predictMidRep, eval=FALSE}
# load points and variable data
vpointFolder <- 'C:/Users/deinesji/Google Drive/GEE_validation/validationSets'
p2007 <- read.csv(paste0(vpointFolder,'/2007_test3_variables_midRep_all.csv'))
p2010 <- read.csv(paste0(vpointFolder,'/2010_test3_variables_midRep_all.csv'))

# par down dfs
#unique(p2007$certainty)
p2007 <- p2007[ , -which(names(p2007) %in% c('.geo'))]
p2010 <- p2010[ , -which(names(p2010) %in% c('.geo'))]


# run predictions/classification without dryland soy in classifier
p2007$randFor <- predict(fit500.ann, newdata = p2007, type='response')
p2010$randFor <- predict(fit500.ann, newdata = p2010, type='response')

# 2007 R no soy
r2007_3_ns <- makeConfusion(p2007$randFor, p2007$class)
kable(r2007_3_ns, digits=1)

# 2010 R no soy
r2010_3_ns <- makeConfusion(p2010$randFor, p2010$class)
kable(r2010_3_ns, digits=1)
```

### assess validation points (middle republican)
Use the accuracy assessment exports from GEE validation to compare results between GEE and Rrrr. These currently use the uncleaned classifications from GEE, since I can't replicate that in R.

```{r compareMidrep, cache=TRUE, eval=FALSE}
# load GEE accuracy tables
accuDir <- 'C:/Users/deinesji/Google Drive/GEE_tableExports/Accuracy_PointsforConfusionTables_test4_randFor'
g2007 <- read.csv(paste0(accuDir,
        '/2007_MidRep_confusionData_RRB_test4_randFor_uncleaned_500tree_allClasses_annual.csv'))
g2010 <- read.csv(paste0(accuDir,
        '/2010_MidRep_confusionData_RRB_test4_randFor_uncleaned_500tree_allClasses_annual.csv'))

g2007 <- g2007[ , -which(names(g2007) %in% c('.geo'))]
g2010 <- g2010[ , -which(names(g2010) %in% c('.geo'))]

# extract important columns from r dataset
rColNamesWanted <- c('system.index','class','classNum','randFor')
p2007.less <- p2007[,rColNamesWanted]
p2010.less <- p2010[,rColNamesWanted]

# combine
p2007.less$system.index <- as.character(p2007.less$system.index)
p2010.less$system.index <- as.character(p2010.less$system.index)

g2007$system.index <- as.character(g2007$system.index)
g2010$system.index <- as.character(g2010$system.index)

geeR.2007 <- merge(g2007, p2007.less, by = 'system.index',all=F)
geeR.2010 <- merge(g2010, p2010.less, by = 'system.index',all=F)

# make sure the system index is an ok column to merge on
sum(!(geeR.2007$classNum.x == geeR.2007$classNum.y))

# convert GEE's classifications from numbers to words
key <- data.frame(classification = c(0,1,2),
                  gee_rf = c('dryland','irrigated','noncrop'))

geeR.2007 <- merge(geeR.2007, key)
geeR.2010 <- merge(geeR.2010, key)

# quick check for matches between gee and R
sum(!(geeR.2007$gee_rf == geeR.2007$randFor))
sum(!(geeR.2010$gee_rf == geeR.2010$randFor))

# give percentages
(nrow(geeR.2007) - sum(!(geeR.2007$gee_rf == geeR.2007$randFor))) / nrow(geeR.2007)
(nrow(geeR.2010) - sum(!(geeR.2010$gee_rf == geeR.2010$randFor))) / nrow(geeR.2010)
```

Break it into a confusion table to better compare accuracies

```{r confusion3, cache=TRUE, eval=FALSE}
# 2007 GEE: make and display confusion table
gee2007_3 <- makeConfusion(geeR.2007$gee_rf, geeR.2007$class.x)
kable(gee2007_3, digits=1)

# 2007 R: make and display confusion table
r2007_3 <- makeConfusion(geeR.2007$randFor, geeR.2007$class.x)
kable(r2007_3, digits=1)

# 2010 GEE
gee2010_3 <- makeConfusion(geeR.2010$gee_rf, geeR.2010$class.x)
kable(gee2010_3, digits=1)

# 2010 R: make and display confusion table
r2010_3 <- makeConfusion(geeR.2010$randFor, geeR.2010$class.x)
kable(r2010_3, digits=1)
```


#### Two Classes (binary classification)
Not awful, but check to see if most of the confusion is between noncrop/dryland

```{r compare2class, cache=TRUE, eval=FALSE}
# make keys to convert classifications from 2 classes to 1
key2class.1 = data.frame(gee_rf = c('dryland','irrigated','noncrop'),
                         gee_rf2 = c('notirrigated','irrigated','notirrigated'))
key2class.2 = data.frame(randFor = c('dryland','irrigated','noncrop'),
                         randFor2 = c('notirrigated','irrigated','notirrigated'))
key2class.3 = data.frame(class.x = c('dryland','irrigated','noncrop'),
                         class2 = c('notirrigated','irrigated','notirrigated'))

geeR.2007 <- merge(geeR.2007, key2class.1)
geeR.2007 <- merge(geeR.2007, key2class.2)
geeR.2007 <- merge(geeR.2007, key2class.3)

geeR.2010 <- merge(geeR.2010, key2class.1)
geeR.2010 <- merge(geeR.2010, key2class.2)
geeR.2010 <- merge(geeR.2010, key2class.3)

# quick check for matches between gee and R
sum(!(geeR.2007$gee_rf2 == geeR.2007$randFor2))
sum(!(geeR.2010$gee_rf2 == geeR.2010$randFor2))

# give percentages
(nrow(geeR.2007) - sum(!(geeR.2007$gee_rf2 == geeR.2007$randFor2))) / nrow(geeR.2007)
(nrow(geeR.2010) - sum(!(geeR.2010$gee_rf2 == geeR.2010$randFor2))) / nrow(geeR.2010)
```

That does improve the "consistency" between programs. Or likely, random seeds.

Check to see which is more accurate via confusion table

```{r confusion2, cache=TRUE, eval=FALSE}
# 2007 GEE: make and display confusion table
gee2007_2 <- makeConfusion2(geeR.2007$gee_rf2, geeR.2007$class2)
kable(gee2007_2, digits=1)

# 2007 R: make and display confusion table
r2007_2 <- makeConfusion2(geeR.2007$randFor2, geeR.2007$class2)
kable(r2007_2, digits=1)

# 2010 GEE
gee2010_2 <- makeConfusion2(geeR.2010$gee_rf2, geeR.2010$class2)
kable(gee2010_2, digits=1)

# 2010 R: make and display confusion table
r2010_2 <- makeConfusion2(geeR.2010$randFor2, geeR.2010$class2)
kable(r2010_2, digits=1)
```

